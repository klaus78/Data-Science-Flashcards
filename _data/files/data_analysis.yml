- h2: Data Analysis
  question: What are the two main types of data?
  answer: >
     The two main types of data are
     <br>- numeric.
     <br>- categorical. The variable can be only one of a finite set of values.
       
       
- question: You can divide numerical data into two types. What are they?
  answer: >
    The two types of numerical data are:
    <ul>
    <li><b>interval data</b>. Interval data is a data type that is measured on a scale where all 
    points are at the same distance. Interval data does not have a zero point.
    Without a zero point the concept of multiplication and division is not
    applicable and thus only sum and difference operations can be applied to interval data.
    An example of interval data is the temperature in C and F. You cannot say that 20C is twice
    as hot as 10C. This is equivalent to 50F and 68F which is clearly not as twice as hot.</li>
    <li> <b>ratio data</b>. Ratio data is similar to interval data except that it has a 
    meaningful zero value so that all the sum, subtraction, multiplication and division operations
    can be applied. Some examples of ratio data are the length and the weight.</li>
    </ul>

- question: You can divide categorical data into two types. What are they?
  answer: >
    There are two types of categorical data:
    <ul>
    <li><b>ordinal data</b> = this data has some kind of order but the difference between
    items is not important. An example of ordinal data are the months or the
    happiness state (sad, happy, very happy etc).</li>
    <li><b>nominal data</b> = data without order and without any quantitative value.
    Some examples of nominal data are all cities in the USA, the gender (male/female),
    the color hair (brown, black, blonde etc).</li>
    </ul>


- question: How to find outliers in a dataset?
  answer: >
    Here are some tools and techniques you can use to find outliers: 
    <ul>
    <li>a histogram.</li> 
    <li>a scatter plot.</li>
    <li>a boxplot.</li>
    <li>the interquartile range (IQR) and say that outliers are outside of the 1.5 IQR limit.</li>
    <li>The standard deviation and consider as outliers those points that are far more than 3 standard deviations
    from the mean.</li>
    <li>sort the data and look for unusual low or high values.
    </ul>


- h3: Distance metrices
  question: What is the hamming distance?
  answer: >
    The hamming distance is used for categorical features. If all the variables 
    are categorical then the hamming distance is defined as the number of mismatches.

- question: What is the Manhattan (or city block) distance?
  answer: >
    It is the number of horizontal and/or vertical steps to go from point p1 to point 
    p2

- question: What is the Levenshtein distance?
  answer: >
    The Levenshtein distance is the minimum number of single-character edits 
    (insertions, deletions or substitutions) to change one word into one another


- h3: Feature engineering
  question: What are the main techniques of feature engineering?
  answer: >
    The main techniques of feature engineering are
    <ul>
    <li><b>feature selection</b>. It selects a subset of features without
    transforming them</li>
    <li><b>feaure learning</b>. Use ML learning algorithms to extract the best features</li>
    <li><b>feature extraction</b>. transform the existing features into new features. This
    is usually done by dim reduction</li>
    <li><b>feature combination</b>. Combine single features into a more powerful feature</li>
     </ul>    

- question: What are the main purposes of feature selection?
  answer: >
    Reducing the number of features by feature selection is useful for
    <ul>
    <li>making models more understandable</li>
    <li>reducing the training times</li>
    <li>avoid the curse of dimensionality</li>
    <li>reduce the risk of overfitting by removing noise in the data</li>
    </ul>
- question: What are the main techniques of feature selection?
  answer: >
    The main techniques of feature selection are
    <br><br>- filter methods. Statistical techniques are used to evaluate the relationship 
    between indiviual features and the target features. This technique is completely independent 
    of the model
    <br><br>- wrapper method. This consists in training a machine learning model 
    by adding/removing features so you can evauate their effect on the model based on a 
    certain scoring
    <br><br>- embedded methods. The features are selected during the model training
    and more important features are assigned an higher rank. Examples of such
    models are decision trees and lasso regression models


- question: What are some differences between the main techniques of feature selection?
  answer: >
    Some differences between filter and wrapper methods are
    <br><br>- wrapper methods rely on machine learning models while filter methods do not. Filter
    methods rely on statistical values.
    <br><br>- filter methods can fail when there is not enough data to extract meaningful 
    statistical values
    <br><br>- wrapper methods take much more time since they involve training a number of
    machine learning models.
    <br><br>- using features extracted with wrapper methods can lead to machine learning models
    affected by overfitting since those features have been extracted using machine learning
    models.    


- question: What is the Z-score normalization (also called standardization)?
  answer: > 
    The <b>Z-score normalization</b> is a technique that scales the values so that they will have the properties
    of a standard distribution with mean <code>&mu; = 0</code>  and standard deviation <code>&sigma; = 1</code>.
    <br>The formula for the normalization is 
    <br> z = 
    <div class="frac">
      <span>x - &mu;</span>
      <span class="symbol">/</span>
      <span class="bottom">&sigma;</span>
    </div>
    

- question: What is the min-max scaling (also called normalization)?
  answer: >
    It is a technique that scales the values between 0 and 1. 
    <br>The formula for the min max scaling is 
    <br> 
    value_scaled = 
    <div class="frac">
      <span>value_to_scale - min</span>
      <span class="symbol">/</span>
      <span class="bottom">max - min</span>
    </div>

- question: When is Z-score normalization used? When is min-max scaling used instead?
  answer: >
    The <b>Z-score normalization</b> is used when the data has a gaussian distribution.
    <br><br>
    The <b>min-max scaling</b> is more used when the distribution is not gaussian or not known.
    In addition, the min-max scaling works better than the Z-normalization when the 
    standard deviation is very small. Indeed in such case the effect of scaling the data
    between 0 and 1 will not affect the standard deviation significantly since it 
    is already small.

- question: >
    What is the disadvantage of min-max scaling compared to Z-score normalization 
    concerning outliers?
  answer: >
    The min-max scaling is more sensitive to outliers since the data is
    bounded between 0 and 1 which automatically leads to information loss about
    outliers. 
    <br>
    The Z-score normalization is more suited when there are outliers since the
    data is not bounded but simply rescaled to have mean 0 and standard deviation 1.

- question: >
    What kind of algorithms are not affected by feature scaling? 
    Can you make some examples of such algorithms? 
  answer: >
    Any algorithm that is not distance based is not affected by feature scaling.
    <br>
    Examples of algorithms not affected by feature scaling are Naive Bayes, Tree-based
    algorithms and Linear Discriminant Analysis.

- question: How to treat missing values?
  answer: >
    There are several possible approaches to treat missing values:
    <ul>
    <li>remove items with missing values</li>
    <li>replace the missing values</li>
    </ul>

- question: When is it reasonably possible to drop items with missing values?
  answer: When the items to remove are few compared to the size of the training set 

- question: What are the common techniques for replacing missing values?
  answer: >
    When values are missing randomly you can:
    <ul>
    <li>replace the missing values with the mean</li>
    <li>interpolate values</li>
    <li>take the previous or next value</li>
    </ul>

- h3: Correlation
  question: What is correlation? Is correlation related with causation?
  answer: >
    Correlation is any statistical relationship, causal or not, between two variables.
    Correlation does not mean causation.

- question: What range of values can have correlation? What values are significant?
  answer: >
    Correlation is a statistical value that quantifies the dependency between
    two variables.  The correlation value ranges from -1 to +1. The -1 (+1) value represents a 
    perfectly negative (positive) correlation. The close the value to 0 is, the weakest the
    linear correlation is. As a thumb rule you can consider values < -0.5 or > +0.5
    to have a significant relationship.    
   
   
- question: There are three main types of correlation, what are they and when are they used?
  answer: >
    The three most common type of correlation are
    <br><br>- Pearson. It is the most common correlation and is used only with numerica data
    It measures the linear relationship between two variables. It also assumes
    that the variables are normally distributed.
    <br><br>- Kendall. It is a rank correlation measure. It works with interval,
    ratio and ordinal data. It measures how similar ranked orderings are. 
    No linear correlation is assumed.
    <br><br>- Spearman. It is is a rank correlation measure. No linearity is assumed but 
    a monotonic relationship, i.e. an increasing (var1 increases and also var2 increases) 
    or decreasing (var1 decreases and also var2 decreases) relationship.


- question: How can you use correlation for feature selection?
  answer: >
    There are at least two approaches:
    <br>- use the the correlation of each feature with the target. You can keep those features 
    that have a significant correlation, i.e. a correlation
    value < -0.5 or > +0.5. 
    <br>- You can use the pairwise correlation between features. If two features are highly 
    correlated then you can drop one of them since they provide the same information.

- question: How can you use variance for feature selection?
  answer: >
    Features with a low variance can be dropped since (almost) constant features do not provide
    any information.

- h3: Dimensionality reduction
  question: What are the main techniques of dimensionality reduction?
  answer: >
    The main techniques of dimensionality reduction are
    <ul>
    <li>projection</li>
    <li>manifold learning</li>
    <li>autoencoding</li>
    </ul>
    HELP WANTED

- question: >
    PCA is affected by scale. To get the optimal performance out of PCA, 
    which is a crucial first step?
  answer: >
    It is necessary to standardize the data using z-score.
    HELP WANTED

- h3: Text processing
  question: What are some steps involved in the preprocessing of a text?
  answer: >
    The preprocessing of a text can involve
    <ul>
    <li>make text lower case</li>
    <li>remove punctuation</li>
    <li>tokenize the text (split up the words in a sentence)</li>
    <li>remove stop words as they convey grammar rather than meaning</li>
    <li>word stemming (reduce words to their stems)</li>
    </ul>
- question: What is a word cloud?
  answer: >
    The word cloud is a visualization technique for text processing where the most frequent
    words in a text are shown in bigger. 
    <br><br>
    The word cloud is not a really scientific method but it can be very useful to capture the 
    attention of people, for example in presentations. An example of word cloud is
  image: word_cloud.png

- h3: Charts
  question: What is a pie chart? When should it be used / not used?
  answer: >
    A <b>pie chart</b> is basically a circle that is divided into slices. Each slice represents a group.
    The size of each slice is proportional to the numbers of items of that group. 
    For example in the picture below, given a set of different fruits,
    you can see the proportion of each type of fruit. 
    <br><br>
    Pie charts are good at showing the relative quantities of items in an intuitive manner. In particular, pie chars
    are good at showing what groups are more or less predominant. In the picture apples are the predominant fruit.
    <br><br>
    Pie charts should not be used for exact quantitative comparisons of slices, in particular when slices have a similar size.
    Indeed it is hard for the human eye to compare areas. For example, considering the picture, pie charts should not be used 
    to find how much the cherries slide is bigger/smaller than the bananas slice.
  image: pie_chart.png

- question: What is a bar chart? When should it be used?
  answer: >
    A <b>bar chart</b> is a chart that represents categorical data with rectangular bars. The size of each bar is proportional
    to the value represented.
    <br><br>
    A bar chart is useful when you want to compare values. In particular a bar chart can also be used to compare
    values that are pretty similar. In this case a bar chart is a better choice than a pie chart because 
    pie charts are not particularly suitable for comparing similar values. 
  image: bar_chart.png


- question:  What are some difference between a bar chart and a histogram?
  answer: >
    A <b>bar chart</b> 
    <ul>
    <li>shows the frequency of each value of a <u>categorical</u> variable.</li>
    <li>each column represents a single value.</li> 
    <li>there are gaps between columns.</li>
    </ul>
    An <b>histogram</b> 
    <ul>
    <li>is used to represent the distribution of a <u>continuous</u> variable.</li>
    <li>each column represents a range of values.</li>
    <li>there are no gaps between columns.</li>
    <li>the area of each column is proportional to the frequency.</li>
    </ul>
  image: bar_chart_histogram.png

- question: What is a histogram particularly good at?
  answer: >
    A <b>histogram</b> is particularly good at representing grouped data. The frequency of each group is 
    represented by the area of the column. Because the width of the columns is proportional to the width of 
    the groups we can have columns with different column widths. The height of the column is then given by
    frequency / width.

- question: Can you draw a boxplot and explain it?
  answer: >
    A <b>boxplot</b> is a chart specialized in visualizing and comparing ranges.

    <br><br>The elements of a boxplot are:
    <ul>
    <li><i>upper extreme (95th Percentile)</i> = exactly 5 percent of the values in the data are 
    greater than this value (may instead be the highest value if not displayed separately as dots).</li>
    <li>
    <i>lower extreme (5th Percentile)</i> = exactly 5 percent of the values in the data are less than this value 
    (may instead be the smallest value if not displayed separately as dots).
    </li>
    <li><i>lower quartile</i> = lowest value of all quartiles. Quartiles are a set of three points that divide the dataset 
    into four equal parts.</li>
    <li><i>upper quartile</i> = highest value of all quartiles</li>
    <li><i>median</i> = middle value of the sorted dataset</li>
    </ul>
  image: boxplot.png
  
- question: What is a heatmap? When is it used?
  answer: >
    A <b>heatmap</b> is a two-dimensional grid that is used for visualizing numerical data organized in a
    table-like format.
    <br><br> 
    Each cell of the heatmap corresponds to a specific row and column in the data, while the cell color
    represents the magnitude of the corresponding value. As a result, different values are mapped to different 
    colors, allowing to identify similarities in the data.
    <br><br>
    Heatmaps are used to explore relationships and patterns in datasets. Some common uses are
    <ul>
      <li>Correlation Analysis: positive and negative correlations between variables are visualized as
      different colors and thus easy to recognize.</li>
      <li>Confusion Matrix Analysis: the performance of classification models can be put in matrix form
      and displayed by heatmaps.</li>
      <li>Genome Analysis: heatmaps are widely used in genomics to visualize gene expression levels.</li>
    </ul> 
    <br>
    An example of table-like dataset and respective heatmap is shown below: 
  image: heatmap.png

- question: What is a violin plot? When is it particularly useful?
  answer: >
    A <b>violin plot</b> is a statistical data visualization that can be thought of as an extension
    of a boxplot. To be more precise, a violin plot includes all the information contained in a boxplot 
    with the addition of a kernel density plot.
    <br><br>
    While a boxplot shows statistical data such as mean, median and interquartile ranges, a violin plot 
    also includes the data distribution. 
    <br><br>
    A violin plot is particularly useful in the following scenarios:
    <ul>
    <li><b>comparing distributions</b>: by placing the distributions side by side, it is easier
    to compare distributions, allowing for a better exploratory analysis.</li>
    <li><b>multiple modes, skewness or outliers in the data</b>: detecting such elements gives you a
    better understanding of the data.</li>
    </ul>
    


