- h2: Coding Dojos
  h3: Statistics Dojos
  question: >
    Given the conditional tree in the picture in the answer, find the probabilities 
    P(Cake|Coffee), P(Cake'&cap;Coffee), P(Cake), P(Coffee|Cake).
  answer: >
    P(Cake|Coffee), can be read directly from the conditional diagram.
    <br><b>P(Cake|Coffee) = (3/4)</b>
    <br><br>
    To find P(Cake' &cap; Coffee), we use the formula of the conditional probability.
    <br><b>P(Cake' &cap; Coffee) = P(Cake'|Coffee) * P(Coffee) = (1/4) * (2/3) = 1/6</b>
    <br><br>
    To find P(Cake), we need to add P(Cake &cap; Coffee) and P(Cake &cap; Coffee')
    <br><b>P(Cake) = P(Cake &cap; Coffee) + P(Cake &cap; Coffee') = P(Cake|Coffee) * P(Coffee) + P(Cake|Coffee') * P(Coffee')
    = (3/4)*(2/3) + (3/5)*(1/3) = 1/2 + 1/5 = 7/10 = 0.7</b>
    <br><br>
    To find P(Coffee|Cake), we use the formula for the conditional probability and P(Cake) found previously.
    <br><b>P(Coffee|Cake) = P(Coffee &cap; Cake) / P(Cake) = P(Cake|Coffee) * P(Coffee) / P(Cake) = (3/4) * (2/3) / (7/10) = 1/2 * 10/7 = 0.71</b> 
  image: conditional_tree_exercise.png

- question: >
    Given a set of people, 80% of them drink coffee while 20% drink tea. Out of those drinking coffee, 70% put sugar in the coffee.
    Out of those drinking tea, 40% put sugar in the tea. Can you draw the probability tree for this scenario? Use the Bayes's Theorem
    to compute P(coffee|sugar free).
  answer: >
    The probability tree is visible below. Given the Bayes formula
    <br>
    <b>
    P(A|B) =
    <div class="frac">
    <span>P(A) * P(B|A)</span>
    <span class="symbol">/</span>
    <span class="bottom">P(A) * P(B|A) + P(A') * P(B|A')</span>
    </div>
    </b> 
    <br><br>we can find <b>P(coffee|sugar free)</b> as follows
    <br><br>
    <b>
    P(coffee|sugar free) =
    <div class="frac">
    <span>P(coffee) * P(sugar free|coffee)</span>
    <span class="symbol">/</span>
    <span class="bottom">P(coffee) * P(sugar free|coffee) + P(tea) * P(sugar free|tea)</span>
    </div> 
    =
    <div class="frac">
    <span>0.8 * 0.3</span>
    <span class="symbol">/</span>
    <span class="bottom">0.8 * 0.3 + 0.2 * 0.6</span>
    </div> 
     = 0.24 / 0.36 = 2/3
    </b>
  image: probability_tree_coffee_sugar.png

- question: >
    Given 10 people, 7 people likes coffe, 5 likes tea, 4 people likes both. 
    Are the probabilities P(coffee) and P(tea) dependent or independent?
  answer: >
    P(coffee) and P(tea) are independent if P(coffee) x P(tea) = P(coffee &cap; tea).
    <br><br>Let's check whether this is the case or not.
    <b><br><br>P(coffee) = 7/10 = 0.7
    <br>P(tea) = 5/10 = 0.5
    <br>P(coffee &cap; tea) = 4 / 10 = 0.4
    <br>P(coffee) x P(tea) = 0.7 x 0.5 = 0.35</b>
    <br><br>Because P(coffee) x P(tea) is different from P(coffee &cap; tea), it follows that 
    P(coffee) and P(tea) are <u>dependent</u> events.

- question: >
    At a local shop you can buy magic boxes that can contain some money prizes. The box costs 1$. The probability
    of winning 5$ is 0.07 and the probability of winning 10$ is 0.03. If X is the net gain, what is
    the probability distribution P(X)? What are the values of the expectation E(X) and the variance Var(X)?
    How do P(X), E(X) and Var(X) change if the price of a magic box is increased to 1.5$?
  answer: >
    The possible values are -1$ (buying a magic box without winning), 4$ (buying a magic box and winning 5$) and 
    9$ (buying a magic box and winning 10$).
    The <b>probability distribution P(X)</b> is given by all possible values (-1, 7, 14) and their probabilities
    (0.9, 0.07, 0.03). 
    <br><br>
    The <b>expectation E(X)</b> is<br>
    <b>E(X) = &mu; = -1*0.9 + 4*0.07 + 9 * 0.03 = -0.9 + 0.28 + 0.27 = -0.35</b>
    <br> The expected long term net gain is -0.35$
    <br><br>
    The <b>variance Var(X)</b> is<br>
    <b>Var(X) = (-1+0.35)<sup>2</sup>*0.9 + (4+0.35)<sup>2</sup>*0.07 + (9+0.35)<sup>2</sup>*0.03 
    = 0.38 + 1.32 + 2.62 = 4.32$</b>
    <br><br>
    If the price of the magic box is increased to 1.5$, the values change but the probabilities remain the same.
    The new data distribution Y can then be obtained from a linear transformation of the original data distribution as follows
    <br>
    <b>P(Y) = aP(X) + b.</b> 
    <br>
    In this example a = 1 and b = 0.5. E(Y) and Var(Y) can be then computed as 
    <br><br>
    <b>E(Y) = a E(X) + b = -0.35 + 0.5 = 0.15$</b>
    <br>
    <b>Var(Y) = a<sup>2</sup>Var(X) = 4.32$</b>

- question: >
    Given a restaurant 1 with prices (3$, $4$, 5$) and probability (0.6, 0.3, 0.1) and a restaurant 2 with prices (2$, 6$, 7$) and
    probability (0.8, 0.15, 0.05), what is the difference in price between the two restaurants?
  answer: >
    The average price for each restaurant is
    <br><b>E(R1) = 3*0.6 + 4*0.3 + 5*0.1 = 3.5$
    <br><br>E(R2) = 2*0.8 + 6.0.15 + 7*0.05 = 2.85$</b>
    <br><br>The variance of the price is 
    <br><b>Var(R1) = (3-3.5)<sup>2</sup>*0.6 + (4-3.5)<sup>2</sup>*0.3 + (5-3.5)<sup>2</sup>*0.1 = 0.45
    <br>Var(R2) = (2-2.85)<sup>2</sup>*0.8 + (6-2.85)<sup>2</sup>*0.15 + (7-2.85)<sup>2</sup>*0.05 = 2.93
    </b>
    <br><br>
    The difference in price between the two restaurant and the respective variance is
    <br><b>E(R1 - R2) = E(R1) - E(R2) = 3.5 - 2.85 = 0.65$ 
    <br>Var(R1 - R2) = Var(R1) + Var(R2) = 0.45 + 2.93 = 3.38</b>   

- question: >
    There is a race between 12 Ferrari cars, 8 Mercedes cars and 5 Lamborghini cars. What is the probability
    that the 5 Lamborghini cars will finish the race consecutively? Suppose that each Lamborghini has the same probability
    of winning.
  answer:
    We are not interested in the order of the individual cars but on the car type at each position. Since the Lamborghini
    cars are at consecutive positions, they can be treated as a single item. We need to find the number of ways in which
    the 5 Lamborghini cars can finish the race consecutively. We also need to find the number of ways the race can be finished
    irrespective of the car types.  
    We use the formula for computing the number of arrangements of k objects where j and k of them are of the same type
    <br><b><div class="frac">
      <span>n!</span>
      <span class="symbol">/</span>
      <span class="bottom">j! k!</span>
    </div></b>
    <br>The number of ways 5 Lamborghini cars can finish the race consecutively is
    <b><div class="frac">
      <span>(20 + 1)!</span>
      <span class="symbol">/</span>
      <span class="bottom">12! 8!</span>
    </div></b>. Notice that we added 1 to the numerator because we consider the 5 Lamborghini cars as a single item.
    <br>
    The number of ways the race can be finished irrespective of the car types is
    <b><div class="frac">
      <span>25!</span>
      <span class="symbol">/</span>
      <span class="bottom">12! 8! 5!</span>
    </div></b>.
    <br>The searched probability is 
    <b><div class="frac">
      <span>(20 + 1))!</span>
      <span class="symbol">/</span>
      <span class="bottom">12! 8!</span>
    </div> &middot; 
    <div class="frac">
      <span>12! 8! 5!</span>
      <span class="symbol">/</span>
      <span class="bottom">25!</span>
    </div> = 
    <div class="frac">
      <span>21! 5!</span>
      <span class="symbol">/</span>
      <span class="bottom">25!</span>
    </div> = 3.95 &middot; 10<sup>-4</sup></b>

- question: Given 12 animals, how many distinct arrangements are there if you pick 5 of them?
  answer: >
    To find the number of distinct arrangements we can use the formula for the combinations
    <br><b><div class="frac">
      <span>n!</span>
      <span class="symbol">/</span>
      <span class="bottom">k! (n-k)!</span>
    </div></b> = 
    <b><div class="frac">
      <span>12!</span>
      <span class="symbol">/</span>
      <span class="bottom">5! (12-5)!</span>
    </div></b> = 792
  
- question: >
    The probability of winning a game is 0.2. Can you find
    <ul>
    <li>the probability you will succeed at your 5th attempt after 4 failures</li>
    <li>the probability you will succeed in 7 or less attempts</li>
    <li>the probability you will need more than 7 attempts to succeed</li>
    <li>the expected number of attempts you need to succeed</li>
    <li>the variance of the expected number of attempts you need to succeed</li>
    </ul>
  answer: >
    This is an example of geometric distribution because we have a set of independent trials. 
    Let <code>p = 0.2</code> be the probability of success and <code>q = 1-p = 0.8</code> the probability of failure.
    <ul>
      <li>The probability you will succeed at your 5th attempt after 4 failures is
      <br><b>P(X=5) = q<sup>4</sup> &middot; p = 0.8<sup>4</sup> &middot; 0.2 = 0.082</b>
      </li>
      <li>The probability you will succeed in 7 or less attempts is 1 minus the probability of failing 7 times.
      <br><b>P(X<=7) = 1 - q<sup>7</sup> = 1 - 0.8<sup>7</sup> = 0.79</b>
      </li>
      <li>The expected number of attempts you need to succeed is the expectation of the geometric distribution 
      <br><b>E(X) = 1 / p = 1 / 0.2 = 5</b>
      </li>
      <li>the variance of the expected number of attempts you need to succeed is found with the variance of a geometric distribution
      <br><b>Var(X) = q / p<sup>2</sup> = 0.8 / 0.2<sup>2</sup> = 20</b>
      </li>
    </ul>
- question: Given 6 questions where each question has 4 possible answers, what is the probability of answering 5 questions correctly?
  answer: >
    For this case we can use the formula of the binomial distribution 
    <b>P(X = r) = <sup>n</sup>C<sub>r</sub> &nbsp; p<sup>r</sup> &nbsp; q<sup>n - r</sup></b>. 
    Indeed we have the following conditions, that are typical for a binomial distribution&colon;
    <ul>
    <li>a limited number of trials (5)</li>
    <li>the probability of answering correctly a question is independent of the other questions</li>
    <li>each answer can either be correct or wrong.</li>
    </ul>
    <br>In our case we have <code>r = 5</code> number of answers correct, <code>p = 0.25</code> probability of answering correctly a question,
    <code>q = 0.75</code> probability of answering wrongly a question, <code>n = 6</code> total number of questions.
    <br><b>P(X = 5) = <sup>6</sup>C<sub>5</sub> &nbsp; 0.25<sup>4</sup> &nbsp; 0.75<sup>6 - 5</sup> = 
    <div class="frac">
      <span>6!</span>
      <span class="symbol">/</span>
      <span class="bottom">5! (6-5)!</span>
    </div>
    &nbsp; 0.25<sup>4</sup> &nbsp; 0.75 = 0.018</b>

- question: >
    Suppose that you live in a town where in average it can rain twice a week. What is the probability that next week
    it will not rain?
  answer: >
    You know that in this town it rains twice a week. Let <code>X</code> be the distribution of the number of times
    it rains. Since we have the scenario with a set of events happening in a certain interval (in a week it can rain twice) 
    and we know the mean values of times it rains in a week, we can say that <code>X</code> follows a <b>Poisson distribution</b>: 
    <br> <code>X ~ Po(&lambda;)</code> with <code>&lambda; = 2</code> (number of times it rains in a week).
    <br>To calculate the probability that next week it will not rain, we can use the formula of the Poisson distribution:
    <br><b>
    P(X = r) =
    <div class="frac">
    <span>e<sup>-&lambda;</sup> &lambda;<sup>r</sup></span>
    <span class="symbol">/</span>
    <span class="bottom">r!</span>
    </div></b>. 
    <br>In our case we have <code>&lambda; = 2</code> and <code>r = 0</code> (0 rains in a week). It follows that the
    probability that it will not rain next week is
    <br>
    <b>
    P(X = 0) =
    <div class="frac">
    <span>e<sup>-2</sup> 2<sup>0</sup></span>
    <span class="symbol">/</span>
    <span class="bottom">0!</span>
    </div> = e<sup>-2</sup> = 0.153</b>

- question: >
    Suppose that you have a restaurant with a kitchen where, in average, the oven can break once a year and the fridge
    can break twice a year. What is the probability that nothing will break in the kitchen next year?
  answer: >
    Let <code>X</code> and <code>Y</code> be the distributions of the number of malfunctions of the oven and the fridge. 
    Because we know the number of malfunctions in a certain time interval (one year), it follows that <code>X</code> and 
    <code>Y</code> follow a Poisson distribution. Thus we can write <code>X ~ Po(1)</code> and <code>Y ~ Po(2)</code>.
    <br><br>
    To find the probability that nothing breaks in the kitchen next year we need to find <code>P(X + Y) = 0</code>. 
    Because <code>X</code> and <code>Y</code> are indipendent distributions, we can sum the distributions as follows
    <br><code>X + Y ~ Po(3)</code>. 
    <br><br>
    <b>P(X + Y = 0) =
    <div class="frac">
    <span>e<sup>-&lambda;</sup> &lambda;<sup>r</sup></span>
    <span class="symbol">/</span>
    <span class="bottom">r!</span>
    </div> =  
    <div class="frac">
    <span>e<sup>-3</sup> 3<sup>0</sup></span>
    <span class="symbol">/</span>
    <span class="bottom">0!</span>
    </div> = e<sup>-3</sup> = 0.05</b>
    <br>The probability that nothing in the kitchen will break next year is 5%.
    

  
- h3: SQL Dojos
  question: Given a table <code>person(name,age)</code>, sort the records by age ascending and by name descending
  sql: | 
  
    SELECT * FROM person 
    ORDER BY age ASC,name DESC
    
- question: Given a table <code>person(name,age)</code>, select the minimum age, the maximum age, the average age. In addition
    rename the average age to <code>meanAge</code>
  sql: |
  
    SELECT MIN(age), MAX(age), AVG(age) AS meanAge
    FROM person
    
- question: Given a table <code>person(name,age)</code>, select all names that do not start with <code>'R'</code>
  sql: |
  
    SELECT name FROM person 
    WHERE name NOT LIKE 'R%'

- question: >
    Given a table <code>person(name,age)</code>, select all names that start with <code>'R'</code> and end 
    with <code>'A'</code> and do not contain <code>'C'</code>
  sql: |
  
    SELECT name FROM person 
    WHERE name LIKE 'R%A' 
    and name NOT LIKE '%C%'

- question: > 
    Given a table <code>person(name,age)</code>, select all names where the second letter is a <code>'i'</code> and the letter before the last
    letter is a <code>'n'</code>
  sql: |

    SELECT * FROM person 
    WHERE name LIKE '_i%' 
    AND name LIKE '%n_'

- question: >
    Given a table <code>person(name,age)</code>, select all items whose age is one of the following values: 23,56,75.
    Then select all items whose age is NOT one of the previous values.
  sql: |
    
    -- query 1: items with one of the ages below
    SELECT * FROM person 
    WHERE age IN (23,56,75)

    -- query 2: items with NONE of the ages below
    SELECT * FROM person 
    WHERE age NOT IN (23,56,75)

- question: >
    Given a table <code>person(name,age)</code>, select all records whose age is between 20 and 40.
    Then select all records whose age is NOT between the previous values.
  sql: |

    -- age is between 20 and 40
    SELECT * FROM person
    WHERE age between 20 AND 40

    -- age is NOT between 20 and 40
    SELECT * FROM person
    WHERE age NOT between 20 AND 40

- question: What is a JOIN clause? What are the four types of JOIN clauses in SQL?
  answer: >
    A JOIN clause is a query that retrieves records from two or more tables.
    <br><br>
    In SQL there are the following types of JOIN clauses (lets suppose we have two tables):
    <ul>
      <li><b>INNER JOIN</b>: returns records that have matching values in <u>both</u> tables.</li>
      <li><b>LEFT (OUTER) JOIN</b>: returns all records from the left table and all matching records from the right table.</li>
      <li><b>RIGHT (OUTER) JOIN</b>: returns all records from the right table and all matching records from the left table.</li>
      <li><b>FULL (OUTER) JOIN</b>: returns all records that match in the left <u>or</u> in the right table.</li>
    </ul>

- question: Given the tables <code>person(name,age), salary(name,money)</code>, select all records that match in both tables
  sql: |

    SELECT * FROM person
    INNER JOIN salary
    ON person.name = salary.name

- question: >
    Given the tables <code>person(name,age), salary(name,money)</code>, select all records from <code>person</code> and all 
    matching records from <code>salary</code>.
  sql: |

    SELECT * FROM salary
    LEFT JOIN person 
    ON person.name = salary.name

- question: >
    Given a table <code>person(name,age)</code>, show the number of records for each name and rename that column to <code>n</code>.
  sql: |

    SELECT name, COUNT(*) as n
    FROM person
    GROUP BY name

- question: >
    Given a table <code>person(name,age,gender)</code>, show the number of records for each gender, labeling the result as 
    either <code>MALE</code> or <code>FEMALE</code> depending on the value of the <code>gender</code> column. 
    Assume that the <code>gender</code> column can have only values <code>M</code> or <code>F</code>.
  sql: |
  
    SELECT count( * ),
           CASE gender
                WHEN 'M' THEN 'male'
                WHEN 'F' THEN 'female'
           END AS gender
    FROM person
    GROUP BY gender
- question: >
    Given a table <code>person(name)</code> find out the people with the longest <code>name</code> (as number of chars).
  sql : |

    SELECT name
    FROM person
    WHERE length( name ) = ( SELECT max( length( name ) )
                             FROM person );


- h3: Python Dojos
  question: >
    Given a list <code>[3,5,7,9,2,4,7]</code>, print the first two items, all items from the third element and the last two items
  python: |

    mylist = [3,5,7,9,2,4,7]
    # first two items
    mylist[:2]
    # all items from the third
    mylist[3:]
    # last two items
    mylist[-2:]
    
- question: Take a list and concatenate it with another list
  python: |

    list1 = [5,2,7]
    list2 = [6,1,9]
    list1.extend(list2)
    # list1 is the concatenation of list1 and list2
    print(list1)

- question: Create a tuple with 3 and 5 and print the second integer
  python: |

    myTuple = (3,5)
    # prints 5
    print(myTuple[1]) 

- question: Create a dictionary, add a (key, value) pair, try to retrieve that key then a non-existing key.
  python: |

    myDict = {}
    myDict['myKey'] = 'myValue'
    print(myDict.get('myKey')) # prints myValue
    # retrieve the non-existing key
    print(myDict.get('myKey2')) # prints None

- question: >
    Create a <code>doSomething</code> function that calls a <code>createTuple</code> function. 
    <code>createTuple</code> must create a tuple from input params 
    <code>x,y</code>.  In addition call <code>doSomething</code> with a lambda function that sums two params.
  python: |

    def createTuple(x,y):
      return (x,y)

    def doSomething(f,x,y):
      return f(x,y)

    t = doSomething(createTuple,3,6)
    print(type(t))

    doSomething(lambda x,y: x+y, 4,6)

- question: Loop over the first 10 integers and print only the even numbers.
  python: |
  
    for i in range(10):
      if i%2 == 0:
          print(i)
          
- question: Given a list of integers, add 1 to each element of the list by using <i>list comprehension</i>.
  python: |

    a = [4,5,6]
    # 5,6,7
    b = [x+1 for x in a]

- question: >
    Given a string <code>'hello everybody'</code>, print the first three characters, 
    the last two characters and the substring between the third and fifth characters included.  
  python: |
    
    s = 'hello everybody'
    # first three characters
    print(s[:3])
    # last two characters
    print(s[-2:])
    # substring between third and fifth characters included
    print(s[2:6])

- question: >
    Given a string <code>'hello everybody'</code>, find at what position the word 
    <code>'everybody'</code> starts.
  python: |
    
    s = 'hello everybody'
    # let's find the position of 'everyboey'. It starts at position 6.
    pos =  s.find('everybody')

- question: >
    Create a dictionary, add the key-value pairs <code>('one', 1)</code> and <code>('two', 2)</code> and
    retrieve the value for key <code>'two'</code>.
  python: |

    # create dictionary
    mydict = dict()
    # insert key-value ('one', 1)
    mydict['one'] = 1
    # insert key-value ('two', 2)
    mydict['two'] = 2

    # you could also insert both pairs with a single command
    # mydict.update({'one':1, 'two':2})

    # retrieve value for key 'two'
    print(mydict['two'])

- question: >
    Given a dictionary <code>myDic = {'one':1, 'two':2}</code>, get the value for key 'three' and take 3 as default in case the key
    does not exist.
  python: |

    myDic = {'one':1, 'two':2}
    # since the key 'three' does not exist, the default value 3 is returned
    print(myDic.get('three', 3))
  
- h3: Numpy Dojos
  question: What is Numpy?
  answer: >
    <b>Numpy</b> is a Python library for numerical computation. Numpy uses libraries written in C and Fortran and this make it 
    very efficient to work with arrays and matrices. 
    <br><br>
    An interesting aspect of Numpy is that you can define upfront how many bytes a variable will need in memory. This feature
    is not supported in Python standard. 

- question: Create a Numpy array with values (2,6,4) where each value takes 1 byte. Then print out the first and third elements.
  python: |

    import numpy as np
    a = np.array([2,6,4], dtype = np.int8)
    # print first and third elements
    print(a[[0,2]])

- question: >
    Create a Numpy array with values from 0 to 4. Then add 3 to each element. Finally show those elements
    that are smaller than 6.
  python: |

    # create array 0..4
    a = np.arange(5)
    # add 3 to each element
    a += 3
    # show elements smaller than 6.
    print(a[a < 6])

- question: Create a numpy array with values (1,4,7,10).
  python: |

    np.arange(start=1, stop=11, step=3)


- question: Create a two-dimensional Numpy array with values from 1 to 4. Then sum the elements by row and by column.
  python: |

    # create a two-dim array
    A = np.array([[1,2],[3,4]])
    # A = array([[1, 2],
    #            [3, 4]])

    # sums by row
    A.sum(axis=0)
    # = array([4, 6])

    # sums by column 
    A.sum(axis=1)
    # = array([3, 7])
    
- question: Create a 2x2 array of random integers with values from 0 to 10 inclusive.
  python: |
    
    np.random.randint(low=1, high=11, size=(2,2))

- question: Create an 3x2 array of only zeros. Then print the type of data.
  python: |
    
    z = np.zeros(shape=(3,2))
    # print the type of data
    print(z.dtype)
- question: Create a NumPy array with values (3.14, 2.71, 1.62) with a specified data type, and then convert it to a Python list.
  python: |
    
    a = np.array([3.14, 2.71, 1.62], dtype=np.float32)
    # convert to list
    a.tolist()

- question: Create a NumPy array with 10 equally spaced values between 0 and 1.
  python: |
    
    np.linspace(start=0, stop=1, num=10)

- question: Given two NumPy arrays arr1 = [1, 2, 3] and arr2 = [4, 5, 6], perform element-wise addition and multiplication. 
  python: |
    
    arr1 = np.array([1, 2, 3])
    arr2 = np.array([4, 5, 6])
    # element-wise addition
    arr1 + arr2
    # element-wise multiplication
    arr1 * arr2

- question: Reshape the following 1D NumPy array [1, 2, 3, 4, 5, 6] into a 2D array with 2 rows and 3 columns.
  python: |
    
    a = np.array([1, 2, 3, 4, 5, 6])
    # reshape to 2x3
    a.reshape(2,3)

- question: Compute the mean, median, and standard deviation of a NumPy array with random values.
  python: |
    
    a = np.random.rand(10)
    # mean
    a.mean()
    # median
    np.median(a)
    # standard deviation
    a.std()

- h3: Matplotlib and Seaborn Dojos
  question: >
    Visualize a pie chart using Matplotlib for the data <code>fruits = ["Apples", "Bananas", "Cherries", "Apricots", "Pears"]</code> 
    and <code>values = [14, 35, 23, 25, 15]</code>.
  python: |

    import matplotlib.pyplot as plt
    values = [14, 35, 23, 25, 15]
    fruits = ["Apples", "Bananas", "Cherries", "Apricots", "Pears"]
    plt.pie(values, labels = fruits)
    plt.show()

- question: >
    Create a chart with <code>plt.subplots()</code>, plot the values <code>x=[2,3,4]</code>, <code>y=[3,5,4]</code>.
    Assign <code>chart test</code> to the title, <code>test x</code> to the x-axis and <code>test y</code> to the y axis. 
  python: |

    import matplotlib.pyplot as plt
    fig, ax = plt.subplots()
    x = [2,3,4]
    y = [3,5,4]
    ax.plot(x,y)
    ax.set(title="chart test", xlabel="test x", ylabel="test y")

- question: >
    Create a Python dictionary containing 5 bananas, 4 apples and 2 cherries. Then create a plot with <code>plt.subplots()</code>, 
    display the values in a bar chart. Set the chart title to <code>Fruit quantities</code>, the x-axis to <code>Fruit</code> and
    the y-axis to <code>Quantity</code>.
  python: |

    fruits = {'banana': 5, 'apple':4, 'cherry': 2}
    import matplotlib.pyplot as plt
    fig, ax = plt.subplots()
    ax.bar(fruits.keys(), fruits.values())
    ax.set_title('Fruit quantities')
    ax.set_xlabel('Fruit')
    ax.set_ylabel('Quantity')

- question: >
    Given <code>x=[3,5,7]</code> and <code>y=[6,8,2]</code>, create two subplots. 
    In the first one draw the line plot of <code>x</code>, <code>y</code> and in the second one draw a scatter plot of x,y.
  python: |

    import matplotlib.pyplot as plt
    x = [3,5,7]
    y = [6,8,2]
    fig, ax = plt.subplots(ncols=2)
    ax[0].plot(x,y)
    ax[1].scatter(x,y)

- question: >
    Generate two random arrays <code>x</code> and <code>y</code> with a normal distribution, each of 100 samples. Then create
    three plots: plot the histogram of <code>x</code>, the histogram of <code>y</code> and the scatter plot of <code>x</code> versus
    <code>y</code>.
    
  python: |

    import matplotlib.pyplot as plt
    x = np.random.normal(size=100)
    y = np.random.normal(size=100)
    fig, ax = plt.subplots(ncols=3, figsize=(12,5))
    ax[0].hist(x)
    ax[1].hist(y)
    ax[2].scatter(x,y)

- question: >
    Generate a dataframe with three columns <code>a,b,c</code>, where each column contains 10 values with an uniform distribution. 
    Then plot the three columns in a bar chart.
  
  python: |

    import pandas as pd
    import numpy as np
    # create a 2D array with 10 rows and 3 columns. Each column
    # has then 10 values with uniform distribution
    x = np.random.rand(10,3)
    # create a dataframe
    df = pd.DataFrame(x, columns=['a','b','c'])
    df.plot.bar()

- question: >
    Create the following dataset <code>
    df = pd.DataFrame({'age':[44, 67, np.nan], 'money':[500,700,550], 'color':['red', 'green','blue']})</code>. Replace the 
    <code>np.nan</code> value with the mean of the other ages. Then display a scatter plot where each point has the given color.

  python: |

    # create dataframe
    df = pd.DataFrame({'age':[44, 67, np.nan], 'money':[500,700,550], 'color':['red', 'green','blue']})
    # replace na value with mean age
    df.fillna(df.age.mean(), inplace=True)
    # display the scatter plot
    df.plot.scatter(x='age', y='money', c='color')

- question: >
    Create two arrays <code>x</code> and <code>y</code>, each containing 30 values that are normally distributed. Then
    display them in a scatter plot and include a vertical and a horizontal line that divide each axis into two
    equal parts.

  python: |

    import numpy as np
    import matplotlib.pyplot as plt
    # generate x,y with random distr.
    x = np.random.randn(30)
    y = np.random.randn(30)
    fig, ax = plt.subplots()
    # scatter plot
    ax.scatter(x,y)
    # horizontal line
    ax.axhline(y.mean())
    # vertical line
    ax.axvline(x.mean()) 

- question: >
    Generate two random arrays: <code>x1</code>, which should contain 30 integers between 2 and 20, 
    and <code>x2</code>, which should contain 100 integers between 1 and 10, both uniformly distributed. 
    Next, create two plots side by side that share the same y-axis, one for <code>x1</code> and one for <code>x2</code>. 
    Label the title of each plot as <b>x1 plot</b> and <b>x2 plot</b> respectively. 
    Lastly, give the entire figure a common title such as <b>My Plots</b>. 

  python: |

    fig, (ax1,ax2) = plt.subplots(nrows=1, ncols=2, sharey = True)
    x1 = np.random.randint(2,20,30)
    x2 = np.random.randint(1,10,100)
    ax1.plot(x1)
    ax1.set_title("x1 plot")
    ax2.plot(x2)
    ax2.set_title("x2 plot")
    # set common title
    fig.suptitle("My plots")

- question: >
    Generate a random array with 10 rows and 3 columns. Display the values in a bar chart with the 
    <code>dark_background</code> style.

  python: |

    import matplotlib.pyplot as plt
    import numpy as np
    import pandas as pd
    # create a random array of size 10x4
    data = np.random.randn(10,4)
    df = pd.DataFrame(data)
    # use the 'dark_background' style 
    plt.style.use('dark_background')
    # display a bar chart
    df.plot.bar()

- question: >
    Generate a random dataset with 10 rows and 2 columns. Display the values in a scatter plot and limit the x-axis between
    0.2 and 0.6.

  python: |

    import matplotlib.pyplot as plt
    import numpy as np
    import pandas as pd
    x = np.random.rand(10,2)
    df = pd.DataFrame(x, columns=['a','b'])
    fig, ax = plt.subplots()
    ax.set_xlim([0.2, 0.6])
    ax.scatter(x=df['a'],y=df['b'])

- question: >
    Given the two series <code>s1 = [3,4]</code> and <code>s2 = [5,7]</code>, create a dataframe
    and call the columns <code>c1</code> and <code>c2</code>. Finally display the dataframe in a 
    heatmap with title <code>My heatmap</code>.

  python: |

    import seaborn as sns
    import matplotlib.pyplot as plt
    import pandas as pd
    # create dataframe
    s1 = [3,4]
    s2 = [5,7]
    df = pd.DataFrame([s1,s2], columns=['c1','c2'])
    # Creating the heatmap using Seaborn
    sns.heatmap(df, annot=True)
    # set the title
    plt.title('My heatmap')
    plt.show()

- question: >
    Given some salaries of engineers <code>[70,72,76,82,69,75]</code> and workers <code>[50,52,56,32,49,55]</code>,
    create a dataframe with a column for each salary group and display the dataframe in a violin plot.

  python: |

    import matplotlib.pyplot as plt
    import seaborn as sns
    import pandas as pd
    import numpy as np

    engineer_salary = [70,72,76,82,69,75]
    worker_salary = [50,52,56,32,49,55]
    data = {
        'engineer salary': [70,72,76,82,69,75],
        'worker salary': [50,52,56,32,49,55]
    }
    df = pd.DataFrame(data=data) 
    sns.violinplot(data=df, palette='muted', inner='quart')
    plt.title('Salary Distribution')
    plt.xlabel('Job')
    plt.ylabel('Salary')
    plt.show()

 
- question: >
   Create a line plot for the function y = x^2 for x values ranging from -5 to 5. Label the axes and give the plot a title.
  python: |

    import matplotlib.pyplot as plt
    import numpy as np
    x = np.arange(-5,5)
    y = x**2
    plt.plot(x,y)
    plt.xlabel('x')
    plt.ylabel('y')
    plt.title('y = x^2')

- question: >
   Visualize a horizontal bar chart for the top 10 countries with the highest population. Use sample data or fetch real data from a dataset. Label the countries on the y-axis and their populations on the x-axis.
  python:  |
  
      import matplotlib.pyplot as plt
      import pandas as pd
      import numpy as np
      # create a dataframe with countries and population
      countries = ['China', 'India', 'USA', 'Indonesia', 'Pakistan', 'Brazil', 'Nigeria', 'Bangladesh', 'Russia', 'Mexico']
      population = [1439323776, 1380004385, 331002651, 273523615, 220892340, 212559417, 206139589, 164689383, 145934462, 128932753]
      df = pd.DataFrame({'country':countries, 'population':population})
      # sort by population
      df.sort_values('population', ascending=False, inplace=True)
      # plot horizontal bar chart
      plt.barh(df.country[:10], df.population[:10])
      plt.xlabel('Population')
      plt.ylabel('Country')
      plt.title('Top 10 countries by population')

- question: >
   Visualize a 3D surface plot of a mathematical function, such as z = x^2 + y^2. Add labels to the axes and a title to the plot.
  python:  |

      import matplotlib.pyplot as plt
      import numpy as np
      from mpl_toolkits.mplot3d import Axes3D
      # create a 3D plot
      fig = plt.figure()
      ax = fig.add_subplot(111, projection='3d')
      # create x,y
      x = np.arange(-5,5)
      y = np.arange(-5,5)
      # create a meshgrid
      X, Y = np.meshgrid(x, y)
      # create z
      Z = X**2 + Y**2
      # plot the surface
      ax.plot_surface(X, Y, Z)
      # set labels
      ax.set_xlabel('x')
      ax.set_ylabel('y')
      ax.set_zlabel('z')
      # set title
      ax.set_title('z = x^2 + y^2')


- h3: Pandas Dojos
  question: What are the two main data structures of Pandas?
  answer: >
    The two main data structures of Pandas are 
    <ul>
      <li><b>Series</b>: it is given by a one-dimensional arrays and an associated array of labels, called indices. Each element
      in the array has a respective index.</li>  
      <li><b>Dataframe</b>: it is a tabular data structure with rows and columns that behind the scenes 
      is a collection of <i>Series</i>.</li>
    </ul>

- question: What is the differences between a Pandas series and a standard Python list?
  answer: >
    A Python list and a Pandas series look at first sight equal. The difference is that a Pandas
    series has a set of indices, one for each element. By default these indices are integers
    but they can be changed to another data type, strings for example.
  python: |

    import pandas as pd
    standard_array = [2,4,6]
    pandas_series = pd.Series([2,4,6])
    # default values are integers
    pandas_series.index
    # let's change them to chars
    pandas_series.index = ['a','b','c']
  

- question: >
    Create a series with 3 values <code>(4,5,7)</code> and 3 indices <code>('a','b','c')</code>. Then
    print the values and the indices separately.

  python: |

        from pandas import Series
        mySeries = Series([4, 7, 5], index=['a','b','c'])
        # print values 4,7,5
        print(mySeries.values)
        # print index 'a','b','c'
        print(mySeries.index)

- question: >
    Given a series with values <code>(3,5,7)</code>, return the values less than 4 or the values bigger than 6
  
  python: |
  
    import pandas as pd
    s = pd.Series([3,5,7])
    # prints [3,7]
    print(s[ (s < 4) | (s > 6) ])

- question: Given a series <code>pd.Series([4,6,7,4])</code>, find the number of distinct values in it.
  python: |

    mySeries = pd.Series([4,6,7,4])
    num_distinct_values = mySeries.nunique()
    # num_distinct_values is equal to 3. The distinct values are 4,6,7. 

- question: Given a series <code>pd.Series(['male', 'female', 'male'])</code>, map <code>'male'</code> to 0 and <code>'female'</code> to 1. 
  python: |

    myseries = pd.Series(['male', 'female', 'male'])
    mapping = {'male': 0, 'female': 1}
    # map 'male' to 0 and 'female' to 1
    myseries.map(mapping)

- question: > 
    Given a series <code>pd.Series([5,-7,2])</code>, replace the negative numbers with 0.
  python: |

    mySeries = pd.Series([5,-7,2])
    # -7 is replaced with 0
    mySeries[mySeries < 0] = 0

- question: Given a series <code>pd.Series([5,np.nan,2])</code>, replace the <code>nan</code> number with the mean.
  python: |

    mySeries = pd.Series([5,np.nan,2])
    # replace all nan numbers with the mean of the remaining numbers
    mySeries[mySeries.isnull()] = mySeries.mean()

- question: >
    Given a series <code>pd.Series(['John', 'Paul', 'Ringo'])</code>, return a new series where each string is 
    replaced with its first character.
  python: |

    mySeries = pd.Series(['John', 'Paul', 'Ringo'])
    # for each string return the first char
    mySeries.apply(lambda s : s[0]) # [J,P,R]

- question: >
    Given a series <code>pd.Series([4,6,8])</code>, transform it to a new series where values less than 5 are mapped to 0
    and the other values are mapped to 1.
  python: |

    mylist = pd.Series([4,6,9])
    # lambda function with conditional statement
    mylist.apply(lambda x: 0 if x < 5 else 1)

- question: >
    Given list of ages, divide the ages into groups of range ages. For examples ages between 0 and 5 are babys, 
    between 5 and 10 are children and so on. 

  python: |

    pd.cut([3,4,13,14,23,24],bins=[0,5,15,25], labels=['Baby','Child','Young'])

- question: >
    Open a csv file, show the first and last two rows, show the number of rows and columns and show the column names.
  python: |
    
    # content of file.csv
    # name,age,money
    # john,43,2500
    # ringo,32,3420
    # paul,42,5600

    import pandas as pd
    ds = pd.read_csv('file.csv')
    # first row
    ds.head(1)
    # last two rows
    ds.tail(2)
    # number of rows and columns
    ds.shape
    # column names
    ds.columns

- question: 
    Create a dataframe with values <code>[4,6,8]</code> for column <code>c1</code>, 
    <code>[6,7,2]</code> for column <code>c2</code> and <code>[3,5,6]</code> for the index.
    Retrieve the row with index value equals to 3 and the row at position 1. 
  python: |

    # create the dataframe
    df = pd.DataFrame({"c1":[4,6,8], "c2": [6,7,2]})
    # set the index array
    df.index = [3,5,6]
    # get row with index 3
    df.loc[3]
    # get row at position 1
    df.iloc[1]


- question: Given a dataframe, sort the values by a column and show how many different items there are in that column
  python: |

    # sort by column 'name'
    ds.sort_values(['name'])
    # show different number of items in column
    ds['name'].value_counts()

- question: Given a dataframe, show all columns of row 2, then show the number of null values for all columns.
  python: |
    
    import pandas as pd
    data = {'Name':['Jeff','Paul','Roger','George'], 'Age':[48,26,17,64],
            'Role':['Tecnician', 'Programmer','Student',np.nan],
            'Salary':[46000,57000,8000,120000]}
    df = pd.DataFrame(data) 
    # show all columns of row 2
    df.loc[2,:]
    # number of null values for each column
    df.isnull().sum()

- question: Given a dataframe, drop the <code>name</code> and <code>age</code> columns. Try to use at least two different approaches.
  python: |

    # let's suppose you have a dataframe df

    # approach 1 to remove the columns. 
    df.drop(['name','age'], axis=1)

    # approach 2
    df.drop(columns = ['name','age'])
  
- question: >
      Given a dataframe with a numeric column <code>Age</code> that has some null values, replace the null values with the
      average age.
  python: |

      # Lets create a dataframe that has a column Age where one value is null
      pd.DataFrame(data)
      data = {'Name':['Jeff','Paul','Roger','George'], 'Age':[np.nan,26,17,64]}
      df = pd.DataFrame(data)
      # let's find the average age
      mean_age = df.Age.mean()
      # replace null values with mean_age.
      df.Age.fillna(mean_age, inplace=True)


- question: >
    Given a list of ages <code>[3,7,14,18,20,25,29]</code>, divide the ages into three bins: child (0-14), 
    young (14-21) and adult (> 21).
  python: |

    # define a list of ages
    ages = [3,7,14,18,20,25,29]
    # define the bins (0-14), (14-21), (21-100)
    mybins = [0,14,21,100]
    # each bin is assigned a label
    mylabels = ['child', 'young', 'adult']
    res = pd.cut(ages, bins = mybins, labels = mylabels)
    # the result is 
    # ['child', 'child', 'child', 'young', 'young', 'adult', 'adult']  

- question: >
    Given a dataset <code>'age':[35,40,45,56,22,19], 'salary':[32,43,56,75,18,16]</code>, divide the salary into three bins: 
    poor (0-20), medium(20-45), rich(>45). Then find the average age for the poor, medium and rich bins.
  python: |

    # create the dataset
    df = pd.DataFrame({'age':[35,40,45,56,22,19], 'salary':[32,43,56,75,18,16]})
    # define salary bins
    mybins = [0,20,45,100]
    # define a label for each bin
    mylabels = ['poor','medium','rich']
    # create a new column 'salary_bin'
    df['salary_bin'] = pd.cut(df.salary, bins = mybins, labels = mylabels)
    # create a pivot table with 
    df.pivot_table(values='age',index='salary_bin')


- question: >
    Create a DataFrame from a dictionary where each key represents a column name and the corresponding value is a list of values for that column. Display the first few rows of the DataFrame.
  python: |
  
      import pandas as pd
      data = {'Name':['Jeff','Paul','Roger','George'], 'Age':[48,26,17,64],
              'Role':['Tecnician', 'Programmer','Student','Manager'],
              'Salary':[46000,57000,8000,120000]}
      df = pd.DataFrame(data) 
      df.head()

- question: >
    Filter a DataFrame to show only rows that meet specific conditions. For example, display rows where a certain column's value is greater than a particular threshold.
  python: |
  
      import pandas as pd
      data = {'Name':['Jeff','Paul','Roger','George'], 'Age':[48,26,17,64],
              'Role':['Tecnician', 'Programmer','Student','Manager'],
              'Salary':[46000,57000,8000,120000]}
      df = pd.DataFrame(data) 
      # show only rows where salary is greater than 50000
      df[df['Salary'] > 50000]

- question: >
    Reshape a DataFrame using pivot tables or other reshaping techniques to make it suitable for analysis or visualization.
  python: |
  
      import pandas as pd
      data = {'Name':['Jeff','Paul','Roger','George'], 'Age':[48,26,17,64],
              'Role':['Tecnician', 'Programmer','Student','Manager'],
              'Salary':[46000,57000,8000,120000]}
      df = pd.DataFrame(data) 
      # reshape the dataframe
      df.pivot_table(values='Age',index='Role')

- question: >
    Merge two DataFrames together based on a common column or index and display the resulting merged DataFrame.
  python: |
  
      import pandas as pd
      data1 = {'Name':['Jeff','Paul','Roger','George'], 'Age':[48,26,17,64],
              'Role':['Tecnician', 'Programmer','Student','Manager'],
              'Salary':[46000,57000,8000,120000]}
      data2 = {'Name':['Jeff','Paul','Roger','George'], 'Age':[48,26,17,64],
              'Role':['Tecnician', 'Programmer','Student','Manager'],
              'Salary':[46000,57000,8000,120000]}
      df1 = pd.DataFrame(data1) 
      df2 = pd.DataFrame(data2) 
      # merge the two dataframes
      pd.merge(df1, df2, on='Name')
  
- h3: Machine Learning Dojos
  question: >
    Create a dataframe from <code>{'a': [2,4,6], 'b': [9,5,3], 'y':[1,2,5]}</code>,
    where <code>y</code> denotes the label column. Create a <code>X</code> dataframe with the feature columns
    and a <code>y</code> dataframe with the label column. Finally split each dataframe into a training and
    a test dataframe, where the test dataframe has 30% of the items.
  python: |

    import pandas as pd
    from sklearn.model_selection import train_test_split
    df = pd.DataFrame({'a':[2,4,6], 'b':[9,5,3], 'y':[1,2,5]})
    X = df.drop(columns='y', axis=1)
    y = df['y']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) 

- question: >
    Create a dataframe from <code>{'a':['a','b','c']}</code> and convert the text feature to a
    numerical feature using the <code>OneHotEncoder</code> class of the <code>sklearn</code> library. 

  python: |

    import pandas as pd
    from sklearn.preprocessing import OneHotEncoder
    from sklearn.compose import ColumnTransformer
    df = pd.DataFrame({'a':['a','b','c']})
    one_hot = OneHotEncoder()
    transformer = ColumnTransformer([('one_hot',
                                      one_hot,
                                      ['a'] )],
                                      remainder='passthrough')
    transformed_df = pd.DataFrame(transformer.fit_transform(df))

- question: >
    Create a dataframe from <code>{'a':[6,8,6, np.NaN]}</code> and replace the <code>NaN</code> value
    with the most frequent value using the <code>SimpleImputer</code> class of the <code>sklearn</code> library.

  python: |

    import pandas as pd
    import numpy as np
    from sklearn.impute import SimpleImputer
    from sklearn.compose import ColumnTransformer
    my_imputer = SimpleImputer(strategy="most_frequent")
    df = pd.DataFrame({'a':[6,8,6, np.NaN]})
    imputer = ColumnTransformer([('imp',my_imputer, ['a'])])
    df_filled = pd.DataFrame(imputer.fit_transform(df))

- question: >
    Load the <code>california housing</code> dataset from sklearn and create a training and a test dataset.
    The test dataset must contains 20% of the total data points. Then train a linear regression with 
    the <code>Ridge</code> algorithm and print the score.

  python: |

    import numpy as np
    import pandas as pd
    from sklearn.datasets import fetch_california_housing
    from sklearn.model_selection import train_test_split
    from sklearn.linear_model import Ridge

    np.random.seed(42)
    ds = fetch_california_housing()
    df = pd.DataFrame(ds['data'], columns = ds['feature_names'])
    df['MedHouseVal'] = ds['target']
    X = df.drop('MedHouseVal', axis=1)
    y = df['MedHouseVal']
    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)
    model = Ridge()
    model.fit(X_train, y_train)
    score = model.score(X_test, y_test)
    print(score)
    # With seed 42 you should get score = 0.575

- question: >
    Load the <code>Iris</code> dataset from the <code>sklearn</code> library. 
    Then, train the <code>RandomForestClassifier</code> on it and finally evaluate the result with 
    the <code>cross_val_score</code> metric.

  python: |

    import numpy as np
    import pandas as pd
    from sklearn.datasets import load_iris
    from sklearn.model_selection import train_test_split
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.model_selection import cross_val_score
    np.random.seed(12)
    ds = load_iris()
    df = pd.DataFrame(ds.data, columns=ds.feature_names)
    df['target'] = pd.Series(ds.target)
    X = df.drop('target', axis=1)
    y = df['target']
    model = RandomForestClassifier()
    cross_val_score(model, X,y)
    # As result you should get array([0.96666667, 0.96666667, 0.93333333, 0.96666667, 1.])

- question: >
    Suppose we have some actual results <code>y_act = [1,0,1,1,0]</code> and let <code>y_pred = [1,1,0,1,0]</code> be the 
    results predicted with a classifier. Evaluate the performance of that classifier using the ROC curve.

  python: |

    from sklearn.metrics import roc_curve
    from sklearn.metrics import RocCurveDisplay
    from sklearn.metrics import roc_auc_score
    y_act = [1,0,1,1,0] 
    y_pred = [1,1,0,1,0]
    # compute ROC
    fpr, tpr, threshold = roc_curve(y_act, y_pred)
    # compute the area under curve (auc)
    auc = roc_auc_score(y_act, y_pred)
    # display the ROC and AUC
    roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=auc).plot()
    # you will get auc = 0.5833

- question: >
    Apply the random forest regressor to the california housing dataset. Then evaluate
    the model performance with the R-squared metric.

  python: |

    import numpy as np
    import pandas as pd
    from sklearn.datasets import fetch_california_housing
    from sklearn.model_selection import train_test_split
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.metrics import r2_score

    np.random.seed(1234)
    # load dataset
    ds = fetch_california_housing()
    df = pd.DataFrame(ds['data'], columns = ds['feature_names'])
    df['target'] = ds['target']
    # dependent variables
    X = df.drop('target', axis=1)
    # independent variable
    y = df['target']
    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)
    model = RandomForestRegressor(n_estimators=100)
    model.fit(X_train, y_train)
    model.score(X_test,y_test)
    y_pred = model.predict(X_test)
    r2_score(y_test, y_pred)
    # you should get 0.8049
    
- question: >
    Write a Python script to perform a web scraping task. Visit a website, such as "https://example.com," and scrape 
    the titles and links of the top articles on the homepage. Use the requests library to fetch the HTML content and
    BeautifulSoup for parsing.

  python: |
   
    import requests
    from bs4 import BeautifulSoup
    url = "https://example.com"
    response = requests.get(url)
    soup = BeautifulSoup(response.text, "html.parser")
    # Find and print the titles and links of the top articles
    top_articles = soup.find_all("div", class_="article")
    for article in top_articles:
    title = article.find("h2").text
    link = article.find("a")["href"]
    print(f"Title: {title}")
    print(f"Link: {link}")

- question: >
    Create a movie recommendation system using user ratings data. The goal is to recommend the top 3 movies for a specific 
    user based on their similarity to other users. For the solution you can use the <code>user_ratings.csv</code> dataset.

  python: |

    import pandas as pd
    from sklearn.metrics.pairwise import cosine_similarity

    # Load user ratings dataset
    ratings_data = pd.read_csv("user_ratings.csv")

    # Calculate the similarity matrix between users
    user_similarity = cosine_similarity(ratings_data)

    # Recommend top 3 movies for a specific user (e.g., user 123)
    user_id = 123
    similar_users = list(enumerate(user_similarity[user_id]))
    similar_users.sort(key=lambda x: x[1], reverse=True)

    # Extract and print the top 3 movie recommendations
    top_movie_ids = [user[0] for user in similar_users[1:4]]
    recommended_movies = ratings_data.columns[top_movie_ids]

- question: >
    Implement a Python script that simulates a basic multiplayer game. The game should involve multiple players, each with unique 
    attributes, and allow them to interact in a virtual world. Create classes and methods for character creation, movement, and 
    combat.

  python: |
    class Player:
    def __init__(self, name, health, attack):
        self.name = name
        self.health = health
        self.attack = attack

    def move(self, direction):
        # Implement movement logic
        pass

    def attack_player(self, target_player):
        # Implement combat logic
        pass
    # Create multiple player objects
    player1 = Player("Alice", 100, 20)
    player2 = Player("Bob", 120, 15)

    # Simulate player interactions, movement, and combat
    player1.move("north")
    player2.attack_player(player1)

- question: >
    Create a DataFrame with sample data where you have features ('X1', 'X2', 'X3') and a target column ('y'). Split the data 
    into training and test sets using a 70/30 split ratio.
  python: |
  
      import pandas as pd
      from sklearn.model_selection import train_test_split
      # create a dataframe with sample data
      data = {'X1':[1,2,3,4,5,6,7,8,9,10], 'X2':[11,12,13,14,15,16,17,18,19,20],
              'X3':[21,22,23,24,25,26,27,28,29,30], 'y':[31,32,33,34,35,36,37,38,39,40]}
      df = pd.DataFrame(data) 
      # split the data into training and test sets
      X = df.drop('y', axis=1)
      y = df['y']
      X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)

- question: >
    Implement k-fold cross-validation on a dataset and use it to train and evaluate a machine learning model. Print the cross-validation scores and metrics.
  python: |
  
      import pandas as pd
      from sklearn.model_selection import cross_val_score
      from sklearn.linear_model import LinearRegression
      # create a dataframe with sample data
      data = {'X1':[1,2,3,4,5,6,7,8,9,10], 'X2':[11,12,13,14,15,16,17,18,19,20],
              'X3':[21,22,23,24,25,26,27,28,29,30], 'y':[31,32,33,34,35,36,37,38,39,40]}
      df = pd.DataFrame(data) 
      # split the data into training and test sets
      X = df.drop('y', axis=1)
      y = df['y']
      # create a linear regression model
      model = LinearRegression()
      # perform k-fold cross-validation
      scores = cross_val_score(model, X, y, cv=5)
      # print the scores
      print(scores)
      # print the mean score
      print(scores.mean())

- question: >
    Apply Principal Component Analysis (PCA) to reduce the dimensionality of a dataset and then train a machine learning model on the reduced data. Compare the model's performance 
    before and after dimensionality reduction.
    
  python: |
  
      import pandas as pd
      from sklearn.model_selection import train_test_split
      from sklearn.decomposition import PCA
      from sklearn.linear_model import LinearRegression
      from sklearn.metrics import r2_score
      # create a dataframe with sample data
      data = {'X1':[1,2,3,4,5,6,7,8,9,10], 'X2':[11,12,13,14,15,16,17,18,19,20],
              'X3':[21,22,23,24,25,26,27,28,29,30], 'y':[31,32,33,34,35,36,37,38,39,40]}
      df = pd.DataFrame(data) 
      # split the data into training and test sets
      X = df.drop('y', axis=1)
      y = df['y']
      X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)
      # apply PCA
      pca = PCA(n_components=2)
      X_train_pca = pca.fit_transform(X_train)
      X_test_pca = pca.transform(X_test)
      # train a linear regression model
      model = LinearRegression()
      model.fit(X_train_pca, y_train)
      # evaluate the model
      y_pred = model.predict(X_test_pca)
      r2_score(y_test, y_pred)
      # you should get 0.9999

- question: >
    Load a dataset with imbalanced classes and implement strategies to deal with class imbalance, such as oversampling, undersampling, or using different evaluation 
    metrics like F1-score or AUC-ROC.

  python: |
  
      import pandas as pd
      from sklearn.datasets import make_classification
      from sklearn.model_selection import train_test_split
      from sklearn.linear_model import LogisticRegression
      from sklearn.metrics import f1_score
      # create a dataset with imbalanced classes
      X, y = make_classification(n_samples=1000, n_classes=2, weights=[0.99, 0.01], random_state=1)
      # split the data into training and test sets
      X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)
      # train a logistic regression model
      model = LogisticRegression()
      model.fit(X_train, y_train)
      # evaluate the model
      y_pred = model.predict(X_test)
      f1_score(y_test, y_pred)
      # you should get 0.0

- h3: Deep learning dojos
  question: >
    Implement a simple feedforward neural network using TensorFlow and Keras. Train it on a dataset to perform image 
    classification.
  
  python: |

    # Here's a basic example of a feedforward neural network using TensorFlow and Keras for image classification:

    import tensorflow as tf
    from tensorflow import keras
    # Load the dataset (e.g., MNIST)
    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
    # Preprocess the data
    x_train, x_test = x_train / 255.0, x_test / 255.0
    # Build the neural network model
    model = keras.Sequential([
        keras.layers.Flatten(input_shape=(28, 28)),
        keras.layers.Dense(128, activation='relu'),
        keras.layers.Dropout(0.2),
        keras.layers.Dense(10)
    ])
    # Compile the model
    model.compile(optimizer='adam',
                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                  metrics=['accuracy'])

    # Train the model
    model.fit(x_train, y_train, epochs=5)
    # Evaluate the model
    test_loss, test_acc = model.evaluate(x_test, y_test)

    # This code demonstrates building a simple neural network for image classification on the MNIST dataset.